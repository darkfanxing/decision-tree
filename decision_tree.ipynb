{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599116665360",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# step 1: get data\n",
    "\n",
    "iris_data = np.loadtxt('iris.txt')\n",
    "data = iris_data[:, :4]\n",
    "labels = iris_data[:, 4]\n",
    "\n",
    "split_rate = 0.8\n",
    "x_train = np.zeros((1, 4))\n",
    "x_test = np.zeros((1, 4))\n",
    "y_train = np.zeros((1))\n",
    "y_test = np.zeros((1))\n",
    "\n",
    "for index in range(0, 150, 50):\n",
    "    split_index = index + int(50 * 0.8)\n",
    "    x_train = np.concatenate((x_train, data[index:split_index]), axis=0)\n",
    "    x_test = np.concatenate((x_test, data[split_index: index + 50]), axis=0)\n",
    "\n",
    "    y_train = np.concatenate((y_train, labels[index:split_index]), axis=0)\n",
    "    y_test = np.concatenate((y_test, labels[split_index: index + 50]), axis=0)\n",
    "\n",
    "x_train = x_train[1:]\n",
    "x_test = x_test[1:]\n",
    "y_train = y_train[1:]\n",
    "y_test = y_test[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some utility\n",
    "\n",
    "def count_class(labels):\n",
    "    class_counts = {}\n",
    "    for label_name in np.unique(labels):\n",
    "        class_counts[label_name] = 0\n",
    "\n",
    "    for label in labels:\n",
    "        class_counts[label] += 1\n",
    "    \n",
    "    return class_counts\n",
    "\n",
    "def calc_entropy(labels):\n",
    "    class_counts = count_class(labels)\n",
    "    average_entropy = 0\n",
    "    for _class, count in class_counts.items():\n",
    "        weight_index = count / len(labels)\n",
    "        average_entropy += weight_index * math.log(weight_index, 2)\n",
    "    \n",
    "    return -1 * average_entropy\n",
    "\n",
    "def information_gain(true_labels, false_labels, current_entropy):\n",
    "    weight_index = float(len(true_labels)) / (len(true_labels) + len(false_labels))\n",
    "    test = current_entropy - weight_index * calc_entropy(true_labels) - (1 - weight_index) * calc_entropy(false_labels)\n",
    "    return test\n",
    "\n",
    "def unique_values(data):\n",
    "    return np.array(list(set([value for value in data[:]])))\n",
    "\n",
    "def is_numeric(value):\n",
    "    return isinstance(value, int) or isinstance(value, float)\n",
    "\n",
    "def find_largest_count_of_label(class_counts):\n",
    "    max_count = 0\n",
    "    label = None\n",
    "\n",
    "    for key, value in class_counts.items():\n",
    "        if class_counts[key] > max_count:\n",
    "            max_count = class_counts[key]\n",
    "            label = key\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# step 2: find the best question (split method)\n",
    "\n",
    "class Question():\n",
    "    def __init__(self, feature_number, value):\n",
    "        self.feature_number = feature_number\n",
    "        self.value = value\n",
    "\n",
    "    def compare(self, data):\n",
    "        data = data[self.feature_number]\n",
    "        return data >= self.value if is_numeric(data) else data == self.value\n",
    "\n",
    "    def __repr__(self):\n",
    "        condition = \">=\" if is_numeric(self.value) else \"==\"\n",
    "        return \"Question: feature_{} {} {} ?\".format(self.feature_number, condition, self.value)\n",
    "\n",
    "def split_data(data, labels, question):\n",
    "    true_data = []\n",
    "    true_labels = []\n",
    "    false_data = []\n",
    "    false_labels = []\n",
    "    for index in range(len(data)):\n",
    "        if question.compare(data[index]):\n",
    "            true_data.append(data[index])\n",
    "            true_labels.append(labels[index])\n",
    "        else:\n",
    "            false_data.append(data[index])\n",
    "            false_labels.append(labels[index])\n",
    "    \n",
    "    return np.array(true_data), np.array(true_labels), np.array(false_data), np.array(false_labels)\n",
    "\n",
    "def find_best_split_method(data, labels):\n",
    "    best_gain = 0\n",
    "    best_question = None\n",
    "    current_entropy = calc_entropy(labels)\n",
    "    feature_indices = data.shape[1]\n",
    "\n",
    "    for feature_index in range(feature_indices):\n",
    "        for value in data[:, feature_index]:\n",
    "            question = Question(feature_index, value)\n",
    "            _, true_labels, _, false_labels = split_data(data, labels, question)\n",
    "\n",
    "            if len(true_labels) == 0 or len(false_labels) == 0:\n",
    "                continue\n",
    "\n",
    "            gain = information_gain(true_labels, false_labels, current_entropy)\n",
    "            if gain >= best_gain:\n",
    "                best_gain, best_question = gain, question\n",
    "\n",
    "    return best_gain, best_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: setup the decision tree\n",
    "\n",
    "class DecisionNode():\n",
    "    def __init__(self, question, true_branch, false_branch, depth, data, labels):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "        self.depth = depth\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "class LeafNode():\n",
    "    def __init__(self, labels):\n",
    "        self.predicted_label = find_largest_count_of_label(count_class(labels))\n",
    "\n",
    "class DecisionTree():\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def build_tree(self):\n",
    "        def build_node(data, labels, depth=0):\n",
    "            gain, question = find_best_split_method(data, labels)\n",
    "            if gain == 0:\n",
    "                return LeafNode(labels)\n",
    "\n",
    "            depth += 1\n",
    "\n",
    "            true_data, true_labels, false_data, false_labels = split_data(data, labels, question)\n",
    "            true_branch = build_node(true_data, true_labels, depth)\n",
    "            false_branch = build_node(false_data, false_labels, depth)\n",
    "            \n",
    "            return DecisionNode(question, true_branch, false_branch, depth, data, labels)\n",
    "        \n",
    "        self.tree = build_node(self.data, self.labels)\n",
    "\n",
    "    def print_tree(self):\n",
    "        def print_tree_node(node, spacing=\"\"):\n",
    "            if isinstance(node, LeafNode):\n",
    "                print(\"{} ↘ Predicted label: {}\".format(spacing, node.predicted_label))\n",
    "                return\n",
    "            \n",
    "            if node.depth % 3 == 0:\n",
    "                list_sign = \"■\"\n",
    "            elif node.depth % 3 == 1:\n",
    "                list_sign = \"◆\"\n",
    "            else:\n",
    "                list_sign = \"●\"\n",
    "\n",
    "            print(\"{} <{}>\".format(spacing, node.question))\n",
    "            print(\"{} {} True:\".format(spacing, list_sign))\n",
    "            print_tree_node(node.true_branch, spacing + \"  \")\n",
    "\n",
    "            print(\"{} {} False:\".format(spacing, list_sign))\n",
    "            print_tree_node(node.false_branch, spacing + \"  \")\n",
    "        \n",
    "        print_tree_node(self.tree)\n",
    "    \n",
    "    def classify(self, data, node):\n",
    "        if isinstance(node, LeafNode):\n",
    "            return node.predicted_label\n",
    "\n",
    "        if node.question.compare(data):\n",
    "            return self.classify(data, node.true_branch)\n",
    "        else:\n",
    "            return self.classify(data, node.false_branch)\n",
    "\n",
    "    def predict(self, data):\n",
    "        answers = []\n",
    "        for index in range(len(data)):\n",
    "            answers.append(self.classify(data[index], self.tree))\n",
    "        \n",
    "        return np.array(answers)\n",
    "    \n",
    "    def evaluate(self, data, labels):\n",
    "        answers = self.predict(data)\n",
    "\n",
    "        count = 0\n",
    "        for index in range(len(answers)):\n",
    "            if answers[index] == labels[index]:\n",
    "                count += 1\n",
    "        \n",
    "        print(\"Accuracy is: {}%\".format(round(count * 100 / len(answers)), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<Question: feature_3 >= 1.0 ?>\n ◆ True:\n   <Question: feature_3 >= 1.8 ?>\n   ● True:\n     <Question: feature_2 >= 4.9 ?>\n     ■ True:\n       ↘ Predicted label: 3.0\n     ■ False:\n       <Question: feature_1 >= 3.2 ?>\n       ◆ True:\n         ↘ Predicted label: 2.0\n       ◆ False:\n         ↘ Predicted label: 3.0\n   ● False:\n     <Question: feature_2 >= 5.0 ?>\n     ■ True:\n       <Question: feature_3 >= 1.6 ?>\n       ◆ True:\n         <Question: feature_2 >= 5.8 ?>\n         ● True:\n           ↘ Predicted label: 3.0\n         ● False:\n           ↘ Predicted label: 2.0\n       ◆ False:\n         ↘ Predicted label: 3.0\n     ■ False:\n       <Question: feature_3 >= 1.7 ?>\n       ◆ True:\n         ↘ Predicted label: 3.0\n       ◆ False:\n         ↘ Predicted label: 2.0\n ◆ False:\n   ↘ Predicted label: 1.0\n"
    }
   ],
   "source": [
    "# step 4: build decision tree \n",
    "DecisionTree = DecisionTree(x_train, y_train)\n",
    "DecisionTree.build_tree()\n",
    "DecisionTree.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy is: 100%\n--------------------\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2.,\n       2., 2., 2., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.])"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# evaluate and inference by decision tree\n",
    "\n",
    "DecisionTree.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"-\" * 20)\n",
    "\n",
    "DecisionTree.predict(x_test)"
   ]
  }
 ]
}